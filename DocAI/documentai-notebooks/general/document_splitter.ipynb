{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPZhvzwesGvB"
   },
   "source": [
    "# Document AI General Document Splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-dlkukAsGuQ"
   },
   "source": [
    "This notebook demonstrates how to use Document Splitter to parse a simple PDF document with multiple scanned files to separate documents on page logical boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary Python libraries and restart your kernel after.\n",
    "!python -m pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your Processor Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(developer): Fill these variables with your values before running the sample\n",
    "PROJECT_ID= 'YOUR_GCP_PROJECT_ID'\n",
    "LOCATION = 'eu' # Format is 'us' or 'eu'\n",
    "PROCESSOR_ID = 'YOUR_DOCAI_PROCESSOR_ID' # Create processor in Cloud Console\n",
    "FILE_PATH = '../resources/general/multi-document.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the function to process the document with Document AI python client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Python modules\n",
    "from google.cloud import documentai_v1beta3 as documentai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document_sample(\n",
    "    project_id: str, location: str, processor_id: str, file_path: str\n",
    "):\n",
    "\n",
    "    # Instantiates a client\n",
    "    opts = {\"api_endpoint\": f\"{location}-documentai.googleapis.com\"}\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    # The full resource name of the processor, e.g.:\n",
    "    # projects/project-id/locations/location/processor/processor-id\n",
    "    # You must create new processors in the Cloud Console first\n",
    "    name = f\"projects/{project_id}/locations/{location}/processors/{processor_id}\"\n",
    "\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "    # Read the file into memory\n",
    "    document = {\"content\": image_content, \"mime_type\": \"application/pdf\"}\n",
    "\n",
    "    # Configure the process request\n",
    "    request = {\"name\": name, \"document\": document}\n",
    "\n",
    "    # Recognizes text entities in the PDF document\n",
    "    result = client.process_document(request=request)\n",
    "\n",
    "    document = result.document\n",
    "\n",
    "    print(\"Document processing complete.\")\n",
    "\n",
    "    # For a full list of Document object attributes, please reference this page: https://googleapis.dev/python/documentai/latest/_modules/google/cloud/documentai_v1beta3/types/document.html#Document\n",
    "\n",
    "    document_pages = document.pages\n",
    "\n",
    "    # Read the text recognition output from the processor\n",
    "    text = document.text\n",
    "    print(\"The document contains the following text (first 100 charactes):\")\n",
    "    print(text[:100])\n",
    "    \n",
    "    # Read the detected page split from the processor\n",
    "    print(\"\\nThe processor detected the following page split entities:\")\n",
    "    print_pages_split(text, document)\n",
    "\n",
    "\n",
    "def print_pages_split(text: str, document: dict):\n",
    "    \"\"\"\n",
    "    Document AI identifies possible page splits\n",
    "    in document. This function converts page splits\n",
    "    to text snippets and prints it.    \n",
    "    \"\"\"\n",
    "    for i, entity in enumerate(document.entities):\n",
    "        confidence = entity.confidence\n",
    "        text_entity = ''\n",
    "        for segment in entity.text_anchor.text_segments:\n",
    "            start = segment.start_index\n",
    "            end = segment.end_index\n",
    "            text_entity += text[start:end]\n",
    "        pages = [p.page for p in entity.page_anchor.page_refs]\n",
    "        print(f\"*** Entity number: {i}, Split Confidence: {confidence} ***\")\n",
    "        print(f\"*** Pages numbers: {[p for p in pages]} ***\\nText snippet: {text_entity[:100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the processor on the sample multi-document pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fHBjYjuU8bFL",
    "outputId": "f734d78a-52a6-4f56-b495-ff2a64485a69"
   },
   "outputs": [],
   "source": [
    "process_document_sample(PROJECT_ID, LOCATION, PROCESSOR_ID, FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the output similar to:\n",
    "```\n",
    "Document processing complete.\n",
    "The document contains the following text (first 100 charactes):\n",
    "FakeDoc M.D.\n",
    "HEALTH INTAKE FORM\n",
    "Please fill out the questionnaire carefully. The information you pro\n",
    "\n",
    "The processor detected the following page split entities:\n",
    "*** Entity number: 0, Split Confidence: 0.21864357590675354 ***\n",
    "*** Pages numbers: [0, 1] ***\n",
    "Text snippet: FakeDoc M.D.\n",
    "HEALTH INTAKE FORM\n",
    "Please fill out the questionnaire carefully. The information you pro\n",
    "*** Entity number: 1, Split Confidence: 0.970017671585083 ***\n",
    "*** Pages numbers: [2] ***\n",
    "Text snippet: Invoice\n",
    "DATE: 01/01/1970\n",
    "INVOICE: NO. 001\n",
    "FROM: Company ABC\n",
    "user@companyabc.com\n",
    "TO: John Doe\n",
    "johndoe\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "Congratulations, you've successfully used the Document AI API to extract page logical boundaries from a multipage document. We encourage you to experiment with other documents."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DocAI Splitter Demo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
